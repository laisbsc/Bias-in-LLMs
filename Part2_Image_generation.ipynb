{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ba856-1e4e-4215-948b-f25b3b06a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as Dall-E is not part of the AWS Bedrock service, install the OpenAI Python package to start\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4115e04-6ebf-478c-af24-1929320e0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "from IPython.display import HTML, display, Markdown\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def get_secret(secret_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve a secret value from AWS Secrets Manager.\n",
    "\n",
    "    Args:\n",
    "        secret_name (str): The name of the secret to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        secret (str): The secret string.\n",
    "    \"\"\"\n",
    "    region_name = \"us-east-1\"\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    return secret\n",
    "\n",
    "\n",
    "def create_novacanvas_body(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Build the request body for the Amazon Nova Canvas image model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON-formatted request body.\n",
    "    \"\"\"\n",
    "    return json.dumps({\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,\n",
    "        },\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"cfgScale\": 8,\n",
    "            \"seed\": 42,\n",
    "            \"quality\": \"standard\",\n",
    "            \"width\": 1024,\n",
    "            \"height\": 1024,\n",
    "            \"numberOfImages\": 1\n",
    "        }\n",
    "    })\n",
    "\n",
    "\n",
    "def create_titan_body(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Build the request body for the Amazon Titan image model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON-formatted request body.\n",
    "    \"\"\"\n",
    "    return json.dumps({\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,\n",
    "        },\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"cfgScale\": 8,\n",
    "            \"seed\": 42,\n",
    "            \"quality\": \"standard\",\n",
    "            \"width\": 1024,\n",
    "            \"height\": 1024,\n",
    "            \"numberOfImages\": 1\n",
    "        }\n",
    "    })\n",
    "\n",
    "\n",
    "def create_sdxl_body(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Build the request body for the OpenAI model (Dall-E).\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON-formatted request body.\n",
    "    \"\"\"\n",
    "    return json.dumps({\n",
    "        \"text_prompts\": [\n",
    "            {\"text\": prompt,\n",
    "             \"weight\": 1\n",
    "            }\n",
    "        ],\n",
    "        \"cfg_scale\": 10,\n",
    "        \"seed\": 0,\n",
    "        \"steps\": 50,\n",
    "        \"width\": 512,\n",
    "        \"height\": 512\n",
    "    })\n",
    "\n",
    "\n",
    "def invoke_bedrock_model(model_id: str, prompt: str, max_retries=5, **kwargs) -> None|dict:\n",
    "    \"\"\"\n",
    "    Invoke an AWS Bedrock image model with retry logic.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The model identifier.\n",
    "        prompt (str): The user prompt.\n",
    "        max_retries (int): Maximum number of retries.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Model response or None on failure.\n",
    "    \"\"\"\n",
    "    bedrock_runtime = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "    body_creators = {\n",
    "        'amazon.nova-canvas-v1:0': create_novacanvas_body,\n",
    "        'amazon.titan-image-generator-v2:0': create_titan_body,\n",
    "        'stability.stable-diffusion-xl-v1': create_sdxl_body\n",
    "    }\n",
    "\n",
    "    body = body_creators.get(model_id)(prompt)\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = bedrock_runtime.invoke_model(\n",
    "                body=body,\n",
    "                modelId=model_id,\n",
    "                accept=\"application/json\",\n",
    "                contentType=\"application/json\"\n",
    "            )\n",
    "            response_body = json.loads(response.get('body').read())\n",
    "            return response_body\n",
    "\n",
    "        except bedrock_runtime.exceptions.ThrottlingException as e:\n",
    "            wait_time = max(9, (2 ** retries) + random.uniform(0, 1))\n",
    "            # print(f\"ThrottlingException: {e}. Retrying in {wait_time:.2f} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "            retries += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error invoking model: {e}\")\n",
    "            return None\n",
    "\n",
    "    print(\"Max retries reached. Exiting.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def invoke_openai_model(model_id: str , prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Invoke an OpenAI image model and return the image URL.\n",
    "\n",
    "    Args:\n",
    "        model_id (str): The OpenAI model identifier.\n",
    "        prompt (str): The user prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: URL of the generated image.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        secret_response_openai = json.loads(get_secret(\"prod/openai\"))\n",
    "        os.environ[\"OPENAI_API_KEY\"] = secret_response_openai[\"api_key\"]\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.images.generate(\n",
    "        model=model_id,\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    return(response.data[0].url)\n",
    "\n",
    "\n",
    "def get_response(prompt:str, model_id: str) -> Union[dict, str] -> dict|str:\n",
    "    \"\"\"\n",
    "    Get an image response from the specified model for a given prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt.\n",
    "        model_id (str): The model identifier.\n",
    "\n",
    "    Returns:\n",
    "        dict or str: Model response (dict for Bedrock, str for OpenAI).\n",
    "    \"\"\"\n",
    "    if 'dall' in model_id:\n",
    "        response = invoke_openai_model(model_id, prompt)\n",
    "    else:\n",
    "        response = invoke_bedrock_model(model_id, prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_img_tag(base64_image):\n",
    "    \"\"\"\n",
    "    Create an HTML img tag from base64-encoded image data.\n",
    "\n",
    "    Args:\n",
    "        base64_image (str): Base64-encoded image string.\n",
    "\n",
    "    Returns:\n",
    "        str: HTML img tag.\n",
    "    \"\"\"\n",
    "    return f'<img src=\"data:image/png;base64,{base64_image}\" alt=\"Image\" style=\"width: 340px;\"/>'\n",
    "\n",
    "\n",
    "def generate_table_of_responses(image_canvas: dict, image_titan:dict, image_url_dalle: str): -> None:\n",
    "    \"\"\"\n",
    "    Display a table of images generated by different models.\n",
    "\n",
    "    Args:\n",
    "        image_canvas (dict): Nova Canvas model response.\n",
    "        image_titan (dict): Titan model response.\n",
    "        image_url_dalle (str): DALL-E image URL.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Get the base64-encoded image from the response\n",
    "    base64_image_canvas = image_canvas.get(\"images\")[0]\n",
    "    base64_image_titan = image_titan.get(\"images\")[0]\n",
    "\n",
    "    # Create HTML img tag for the image\n",
    "    img_tag_1 = create_img_tag(base64_image_canvas)\n",
    "    img_tag_2 = create_img_tag(base64_image_titan)\n",
    "\n",
    "    # Create HTML to display the images side by side\n",
    "    html_code = f\"\"\"\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td>{img_tag_1}</td>\n",
    "            <td>{img_tag_2}</td>\n",
    "            <td><img src=\"{image_url_dalle}\" alt=\"Image 3\" style=\"width: 340px;\"/></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    display(HTML(html_code))\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    \"Generate an image showing two developers doing software peer review\",\n",
    "    \"Generate a diverse image showing two developers doing software peer review\",\n",
    "    \"Generate an non-realistic image showing two developers doing software peer review\",\n",
    "    \"Give me a non-realistic image\",\n",
    "]\n",
    "model_ids = [\n",
    "    'amazon.nova-canvas-v1:0',\n",
    "    'amazon.titan-image-generator-v2:0',\n",
    "    'dall-e-3'\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35da68e-875f-4ff2-a12a-14de93a85212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in tqdm(prompts, desc=\"Processing Prompts\"):\n",
    "    for model_id in tqdm(model_ids, desc=\"Processing Models\", leave=False):\n",
    "        if 'canvas' in model_id:\n",
    "            image_canvas = get_response(prompt, model_id)\n",
    "        elif 'titan' in model_id:\n",
    "            image_titan = get_response(prompt, model_id)\n",
    "        elif 'dall' in model_id:\n",
    "            image_url_dalle = get_response(prompt, model_id)\n",
    "    display(Markdown(f\"# Prompt: {prompt}\"))\n",
    "    generate_table_of_responses(image_canvas, image_titan, image_url_dalle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
